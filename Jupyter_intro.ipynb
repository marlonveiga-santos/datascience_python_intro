{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebooks: Introdução\n",
    "\n",
    "<img src = \"https://ibm.box.com/shared/static/jmtb4pgle2dsdlzfmyrgv755cnqw95wk.png\" width = 300, align = \"center\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px;color:green\">\n",
    "<li><a href=\"#ref1\">Introdução</a>\n",
    "<li><a href=\"#ref2\">Começando a análise</a></li>\n",
    "<li><a href=\"#ref3\">Insights</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ref1\"></a>\n",
    "<h1>Introdução</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Jupyter notebook (ou iPython)  é uma ferramenta de análise de dados baseada na linguagem Python que permite a realização dos processo de análise e tratamento de dados em tempo real por meio do navegador ou após a instalação do pacote em seu sistema\n",
    "\n",
    "Com esta ferramenta, você é capaz de utilizar a linguagem Markdown para apresentar A descrição ou Storytelling dos seu dados, dados RAW quando o seu formato é inespecífico e, claro, A linguagem Python, em suas versões 2 ou 3, para injetar a inteligência necessária em sua agenda(notebook) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** \n",
    "- Nos exemplos seguir será utilizada a versão 3 da linguagem Python, porém você pode utilizar a versão 2 caso a conheça, ao selecionar esta opção na parte superior direita da guia principal.\n",
    "- O foco desta agenda não será ensinar a linguagem Python _per se_, mas criar um guia de referência para ser utilizado futuramente caso você queira trilhar a carreira de analista de dados.\n",
    "- Todo o conteúdo foi criado em plataformas livres, e o seu uso e alteração podem ser efetuados sem restrições, embora o crédito ao criador será bem-vindo para que futuras apresentações possam ser desenvolvidas :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Spoiler: o <i>HTML</i> funciona também...</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Criando celulas:</h2> para criar as células será necessário clicar no icone + no menu superior e selecionar o seu tipo como code, Markdown(HTML) ou RAW(sem formatação). Por padrão a celula tem o formato code respeita a versão selecionada a direita do menu principal.\n",
    "Para executar uma célula de código será necessário pressionar ao mesmo tempo as teclas Ctrl e Enter com a célula selecionada ou o botão play no menu superior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primeiro passo: Hello World\n",
    "Inicialmente você irá executar a primeira instrução de codigo no Jupyter, obviamente será o noss Hello World!!!\n",
    "> pressione Ctrl + Enter na celula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello World!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a sintaxe respeita totalmente as regras da linguagem Python e o seu resultado aparece imediatamente abaixo da célula, semelhante a uma saida de console. Dessa forma toda a informa fica agrupada facilmente onde é necessaria\n",
    "> **dica:** Você pode usar esse ambiente para treinar o uso basico das linguagens Python, R e C++(em algumas versões do Jupyter)\n",
    "não será abordado o basico do Python mas essa informação será adicionada em breve aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ref2\"></a>\n",
    "# Começando a análise\n",
    "## Obtendo dados\n",
    "\n",
    "Existem vários formatos para um dataset(conjuntos de dados), .csv, .json, .xlsx  etc. um dataset pode ser armazenado me diferentes locais, como em seu computador ou até mesmo online.\n",
    "Neste ponto, vamos aprender como carregar os nossos datasets no Jupyter Notebook.\n",
    "Em nosso caso, o dataset dos automóveis é uma fonte online, e está no formato CSV (comma separated value). Vamos usar este dataset como exemplo para a nossa leitura de dados.\n",
    "Fonte: https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "Tipo: csv\n",
    "A biblioteca Pandas é uma ferramentra muito útil que nos permite ler numerosos datasets em um dataframe(quadro de dados); a plataforma Jupyter notebook já possui nativamente a **biblioteca Pandas** então tudo o que precisamos é importá-la sem nos preocumarmos com uma instação externa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo os dados\n",
    "Usaremos a função **\"pandas.read_csv()\"**  para ler o aruivo CSV. O caminho do arquivo será atribuido a variavel **path** digitado entre aspas duplas para ser reconhecido como URL.\n",
    "Como os dados a serem bixados não possuem cabeçalhos(nome de coluna) será inserido o argumento **\" headers = None\"**  dentro do método **\"read_csv()\"** evitando assim que o pandas atribua  primeira linha como cabeçalho automaticamente.\n",
    "Você pode atribuir o dataset a qualquer variável que você criar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atribuindo a URL do arquivo online a variavel path\n",
    "path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "# atribuindo a variave df o conteudo de path em formato csv, sem cabeçalho\n",
    "df = pd.read_csv(path,header=None)\n",
    "print(\"Executado com sucesso!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a leitura do dataset, podemos executar o método **`dataframe.head(n)`** para vermos as linhas iniciais do dataset e checar se tudo ocorreu como previsto.\n",
    "Você também pode utilizar o método **`dataframe.tail(n)`** para mostrar as ultimas linhas do dataset\n",
    "**OBS:** O argumento n tem que ser um número inteiro e, caso não seja aferido, o valor default a ser mostrado será de 5 linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando as primeiras 5 linhas do dataframe df\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando as 10 ultimas linhas do dataframe df\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando os cabeçalhos\n",
    "Ao olhar para o nosso dataset, vemos que o pandas atribuiu aos cabeçalhos um valor numerico a partir do 0. \n",
    "\n",
    "Para descrever melhor as informações nós temos que adicionar os nomes das colunas, esta informação está disponível em:  https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "<p></p>\n",
    "<div>Porém, nós temos que adicionar os cabeçalhos maualmente</div>\n",
    "<div>Primeiramente, vamos criar uma lista <b>\"headers\"</b> que inclui todos os nomes de colunas em ordem.</div>\n",
    "<div>então, usaremos a expressão <b>dataframe.columns = headers`</b> para alterar os cabeçalhos pela lista que criamos.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a lista com os nomes das colunas\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterando as colunas pelo valor contido em headers\n",
    "df.columns = headers\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nós também podemos excluir alguns valores da coluna \"price\" como a seguir (Mais detalhes adiante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"price\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ler os valores apenas das colunas são usados os atributos columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o dataset\n",
    "Agora que já tratamos do nosso dataset podemos salvá-lo com o método **`dataframe.to_csv()`** você pode adicionar um caminho para salvar os seus arquivos.\n",
    "\n",
    "Por exemplo, se você quiser salvar o seu dataset \"df\" como \"automobile.csv\" em sua máquina local, utilize a sintaxe abaixo:\n",
    "~~~~\n",
    "df.to_csv(\"automobile.csv\")\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Você pode ler e salvar os arquivos nos seguintes formatos:\n",
    "\n",
    "\n",
    "\n",
    "| Formato  | Ler        | Salvar           |\n",
    "| ------------- |:--------------:| ----------------:|\n",
    "| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n",
    "| json          | `pd.read_json()` |`df.to_json()`    |\n",
    "| excel         | `pd.read_excel()`|`df.to_excel()`   |\n",
    "| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n",
    "| sql           | `pd.read_sql()`  |`df.to_sql()`     |\n",
    "| ...           |   ...          |       ...        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ref3\"></a>\n",
    "# Insights: O básico\n",
    "Depois de converter a nossa informação em um dataframe pandas, é hora de explorarmos o dataset;\n",
    "Existem muitas formas de oobtermos os insights essenciais dos dados para entendermos melhor o nosso dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de dados\n",
    "Os dados possuem diversos tipos.\n",
    "Opricipais tipos armazenados nos dataframes pandas são: `object`, `float`, `int`, `bool` e `datetime64`. em ordem, para aprendermos melhor sobre cada atributo, é sempre bom sabermos qual o tipo de dado de cada coluna. No pandas usamos:\n",
    "~~~~\n",
    "dataframe.dtypes\n",
    "~~~~\n",
    "Que retorna uma série com o tipo de dado de cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checa o tipo de dado de cada coluna do dataframe \"df\" por meio do .dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado mostrado acima no diz claramente, o tipo de dado de \"symboling\" e \"curb-weight\" são `int64`, \"normalized-losses\" é um `object`, e \"wheel-base\" é um `float64`, e etc.\n",
    "Esses tipos de dados podem ser alterados como veremos posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe\n",
    "Se nós quisermos obter uma descrição estatistica de cada coluna, como a enumeração, valor médio e desvio padrão entre outros, nós utilizamos o método `describe`:\n",
    "~~~~\n",
    "dataframe.describe()\n",
    "~~~~\n",
    "Este método nos retorna vários resumos estatísticos, excluindo-se os valores `NaN` (Not a Number).\n",
    "> **nota:** A biblioteca pandas foi criada com o idioma inglês, sendo necessário assim, saber o termo em inglês de seus termos estatísticos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto nos mostra o resumo estatístico de todos os tipos numéricos (int,float) das colunas.\n",
    "Por exemplo, o atributo \"symboling\" tem 205 itens contados, o valor medio desta coluna é 0.83, seu desvio padrão é 1.25, e oseu valor mínimo é -2, Seu 25º percentil é 0, seu 50º percentil é 1, seu 75º percentil é 2, e o seu valor máximo é 3.\n",
    "\n",
    "Todavia, se você quiser analisar todas as colunas, incluindo as do tipo `object`, você pode adicionar o argumento `include = \"all\"` dentro do método como observado abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descreve todas as colunas de \"df\" \n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, nos é apresentado o resumo estatístico de todas as colunas, incluindo as do tipo objeto.\n",
    "Como podemos ver agora, alguns valores nos são apresentados como `NaN`, isso se deve ao fato desses valores não poderem ser representados devido ao tipo de dado que eles possuem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode selecionar colunas específicas do seu dataframe ao adicioná-las como argumento antes da função describe como exemplificada abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['length','compression-ratio']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "Outro método que podemos utilizar para verificar o nosso dataframe é o `info` que pode ser utilizado conforme a sintaxe abaixo\n",
    "~~~~\n",
    "dataframe.info\n",
    "~~~~\n",
    "Ele nos provê um resumo mais conciso(maior) do nosso dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando o info do nosso \"df\"\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele nos apresenta a informação das primeiras 30, e das últimas 20 linhas do nosso dataframe. Também nos mostra que o dataframe possui 205 linhas e 26 colunas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
